

伪造UA字符串
第三方库 fake_uesragent
安装
pip install fake_useragent

from fake_useragent import UserAgent
ua=UserAgent()
print(ua.random)

随机产生UA
ua.random

github中文网
http://www.githubs.cn/



在爬虫项目下创建main.py文件

from scrapy import cmdline
cmdline.execute("scrapy crawl 爬虫名".split())

运行main.py就可以启动项目下的爬虫

demo.py文件中引进说明，在items.py中可以创建多个类

from urllib import urlencode
from scrapy import log
from scrapy.spiders import CrawlSpider
from scrapy.selector import Selector
from scrapy.http import Request, FormRequest
from zhihu.items import ZhihuPeopleItem, ZhihuRelationItem


 yield Request(url,callback=self.parse_people,errback=self.parse_err)

  def parse_people(self, response):
      pass
  def parse_err(self, response):
        log.ERROR('crawl {} failed'.format(response.url))
        
        
        
        
        
        
        
        
