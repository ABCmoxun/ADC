
安装
pip install scrapy-redis

要求
Python 2.7, 3.4 or 3.5
Redis >= 2.8
Scrapy >= 1.1
redis-py >= 2.10


在settings文件中的设置
SCHEDULER = "scrapy_redis.scheduler.Scheduler"              #调度器
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"    #过滤器
SCHEDULER_PERSIST = True                                      #是否停止（停止后，从停止的地方开始爬取信息）

REDIS_URL = 'redis://user:pass@hostname:9001'   #REDIS_URL = 'redis://root:passwd@127.0.0.1:6379'
或者
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
LOG_LEVEL = 'DEBUG'   #


在demo.py文件中
启始网址
 redis_key = 'mycrawler:start_urls'
 redis_key = 'myspider:start_urls'
 
爬虫可以继承这些类
from scrapy.spiders import CrawlSpider     #创建爬虫文件的语法 scrapy genspider pachong_name -t crawl  
class DmozSpider(CrawlSpider):

from scrapy_redis.spiders import RedisCrawlSpider
class MyCrawler(RedisCrawlSpider):

from scrapy_redis.spiders import RedisSpider     #一般用这个类
class MySpider(RedisSpider)：
深度和广度优先
＃使用优先级队列安排请求。（默认）
＃ SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.PriorityQueue'

＃替代队列
# 广度优先
＃ SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue' 
DEPTH_PRIORITY = 1  # 广度优先
# 深度优先
＃ SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'
DEPTH_PRIORITY = -1 # 深度优先





