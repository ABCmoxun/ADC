

# 在scrapy中的middleware中设置use_Agent和代理
import random
import base64

USER_AGENTS=[列表]
PROXIES=[{'ip_port':'127.0.0.1:0000'},
{'ip_port':'','user_passwd':user:passwd}
         {},,,,,]


class RandomUesrAgent(object):
    def process_request(self,request,sprider):
        useragent=random.choice(USER_AGENTS)
        #request.headers.setdefault('User-Agent',useragent)   #二选一
	request.headers['User-Agent']=agent

class RandomProxy(object):
    def process_request(self,request,sprider):
        proxy=random.choice(PROXIES)
        #开放代理
        if proxy['user_passwd'] is None:
            request.meta['proxy']='http://'+proxy['ip_port']
            #request.meta['proxy']='https://'+proxy['ip_port']

        else:   #私密代理
            b64.user_psw=base64.b64encode(proxy['user_passwrd'].encode('utf-8'))
            request.meta['proxy']='http://'+proxy['ip_port']
            request.headers['proxy_Authorization']='basic '+b64.user_psw.decode('utf-8')
            #'basic '有一个空格


在middlewares
在middleware中使用selenium  ！！


在settings文件中开启设置
打开DOWNER_MIDDLEWARE={'douban.middlewares.my_prox':543       #优先级值越小优先极越高,优先级不能相同
		  'douban.middlewares.my_useragent':544 }




USER_AGENT_LIST = ['zspider/0.9-dev http://feedback.redkolibri.com/',
                    'Xaldon_WebSpider/2.0.b1',
                    'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) Speedy Spider (http://www.entireweb.com/about/search_tech/speedy_spider/)',
                    'Mozilla/5.0 (compatible; Speedy Spider; http://www.entireweb.com/about/search_tech/speedy_spider/)',
                    'Speedy Spider (Entireweb; Beta/1.3; http://www.entireweb.com/about/search_tech/speedyspider/)',
                    'Speedy Spider (Entireweb; Beta/1.2; http://www.entireweb.com/about/search_tech/speedyspider/)',
                    'Speedy Spider (Entireweb; Beta/1.1; http://www.entireweb.com/about/search_tech/speedyspider/)',
                    'Speedy Spider (Entireweb; Beta/1.0; http://www.entireweb.com/about/search_tech/speedyspider/)',
                    'Speedy Spider (Beta/1.0; www.entireweb.com)',
                    'Speedy Spider (http://www.entireweb.com/about/search_tech/speedy_spider/)',
                    'Speedy Spider (http://www.entireweb.com/about/search_tech/speedyspider/)',
                    'Speedy Spider (http://www.entireweb.com)',
                    'Sosospider+(+http://help.soso.com/webspider.htm)',
                    'sogou spider',
                    'Nusearch Spider (www.nusearch.com)',
                    'nuSearch Spider (compatible; MSIE 4.01; Windows NT)',
                    'lmspider (lmspider@scansoft.com)',
                    'lmspider lmspider@scansoft.com',
                    'ldspider (http://code.google.com/p/ldspider/wiki/Robots)',
                    'iaskspider/2.0(+http://iask.com/help/help_index.html)',
                    'iaskspider',
                    'hl_ftien_spider_v1.1',
                    'hl_ftien_spider',
                    'FyberSpider (+http://www.fybersearch.com/fyberspider.php)',
                    'FyberSpider',
                    'everyfeed-spider/2.0 (http://www.everyfeed.com)',
                    'envolk[ITS]spider/1.6 (+http://www.envolk.com/envolkspider.html)',
                    'envolk[ITS]spider/1.6 ( http://www.envolk.com/envolkspider.html)',
                    'Baiduspider+(+http://www.baidu.com/search/spider_jp.html)',
                    'Baiduspider+(+http://www.baidu.com/search/spider.htm)',
                    'BaiDuSpider',
                    'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0) AddSugarSpiderBot www.idealobserver.com',
                   ]

也可以添加cookie  request.cookies='cookies'



#资料
https://blog.csdn.net/u013210620/article/details/80283637 
https://chenjiabing666.github.io/2017/03/25/scrapy%E7%9A%84%E4%B8%8B%E8%BD%BD%E5%99%A8%E4%B8%AD%E9%97%B4%E4%BB%B6/
在SpiderMiddleware中 
process_spider_input 是SpiderMiddleware下载完成，执行，然后交给parse处理 
process_spider_output spider处理完成，返回时调用，必须返回包含 Request 或 Item 对象的可迭代对象(iterable)

process_spider_exception return: None,继续交给后续中间件处理异常；含 Response 或 Item 的可迭代对象(iterable)，交给调度器或pipeline

process_start_requests 爬虫启动时调用
--------------------- 
在DownMiddleware1中 
process_request
process_request(request, spider)
 请求需要被下载时，经过所有下载器中间件的process_request调用
        :param request: 
        :param spider: 
        :return:  
            None,继续后续中间件去下载；
            Response对象，停止process_request的执行，开始执行process_response
            Request对象，停止中间件的执行，将Request重新调度器
            raise IgnoreRequest异常，停止process_request的执行，开始执行process_exception

process_response
process_response(request, response, spider)
 spider处理完成，返回时调用
        :param response:
        :param result:
        :param spider:
        :return: 
            Response 对象：转交给其他中间件process_response
            Request 对象：停止中间件，request会被重新调度下载
            raise IgnoreRequest 异常：调用Request.errback

process_exception
process_exception(request, exception, spider)
  当下载处理器(download handler)或 process_request() (下载中间件)抛出异常
        :param response:
        :param exception:
        :param spider:
        :return: 
            None：继续交给后续中间件处理异常；
            Response对象：停止后续process_exception方法
            Request对象：停止中间件，request将会被重新调用下载
-------------------
